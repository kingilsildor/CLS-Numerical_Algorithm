{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06d3e5bf55c941ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Homework set 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-736ff6bc3e0d0696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Monday December 9, 9:00**. **Submit the notebook file with your answers (as .ipynb file) and a pdf printout. The pdf version can be used by the teachers to provide feedback. On canvas there are hints about creating a nice pdf version.**\n",
    "\n",
    "Before you hand in, please make sure the notebook runs, by running \"Restart kernel and run all cells...\" from the Kernel menu.\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b13bc5ed16bce8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd464f55ba436b1c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- Tycho Stam (13303147)\n",
    "- Henry Zwart (15393879)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5a7855ecca9f6be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to import NumPy, Matplotlib. If anything else is needed you can import this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "N.B.1. you are to implement the methods yourself.\n",
    "\n",
    "N.B.2. Tentative distribution of points is 2+1+2+2+2 points (plus 1 point makes 10).\n",
    "\n",
    "Given a function $f$, let $T(f,a,b,m)$ denote the composite trapezoid rule with $m$ subintervals over the interval $[a,b]$. \n",
    "\n",
    "## (a)\n",
    "Approximate the integral of $x^{-3}$ over $[a,b] = [ \\frac{1}{10}, 100 ]$ by the composite trapezoid rule $T(f,a,b,m)$ for $m = 2^k$. Plot the absolute approximation error for different values of $k$. Find the smallest $k$ such that the exact error is less than $\\epsilon = 10^{-3}$. Explain the slow convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNC_EVAL = 0\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    The function to be minimized.\n",
    "    \"\"\"\n",
    "    global FUNC_EVAL\n",
    "\n",
    "    try:\n",
    "        FUNC_EVAL += len(x)\n",
    "    except TypeError:\n",
    "        FUNC_EVAL += 1\n",
    "\n",
    "    return np.power(x, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(f, a, b, m, fa=None, fb=None, fmid=None):\n",
    "    \"\"\"\n",
    "    Composite trapezoidal rule for a function f over the interval [a, b] with m subintervals.\n",
    "\n",
    "    Takes optional keyword arguments fa, fb, fmid, the function evaluations at these\n",
    "    points. If these are not supplied, they are calculated as necessary within the\n",
    "    function. Otherwise the provided values are used. This allows elimination of\n",
    "    unnecessary duplicate evaluations, for instance, in the composite midpoint rule.\n",
    "    \"\"\"\n",
    "    h = (b - a) / m\n",
    "\n",
    "    fa = fa or f(a)\n",
    "    fb = fb or f(b)\n",
    "\n",
    "    endpoint_value = (1 / 2) * (fa + fb)\n",
    "\n",
    "    if m > 1:\n",
    "        midpoint = (a + b) / 2\n",
    "        fmid = fmid or f(midpoint)\n",
    "        midpoint_value = fmid\n",
    "\n",
    "        if m > 2:\n",
    "            left_points = np.linspace(a + h, midpoint - h, (m // 2) - 1)\n",
    "            right_points = np.linspace(midpoint + h, b - h, (m // 2) - 1)\n",
    "            internal_value = f(left_points).sum() + f(right_points).sum()\n",
    "        else:\n",
    "            internal_value = 0\n",
    "    else:\n",
    "        midpoint_value = 0\n",
    "        internal_value = 0\n",
    "\n",
    "    return h * (endpoint_value + midpoint_value + internal_value)\n",
    "\n",
    "\n",
    "def T_simple(f, a, b, m):\n",
    "    \"\"\"\n",
    "    Simple trapezoidal rule for a function f over the interval [a, b] with m subintervals.\n",
    "    \"\"\"\n",
    "    h = (b - a) / m\n",
    "    x = np.linspace(a + h, b - h, m - 1)\n",
    "    return h * ((f(a) / 2) + f(x).sum() + (f(b) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1 / 10, 100.0\n",
    "true_value = 1 / 2 * (1 / 0.1**2 - 1 / 100**2)\n",
    "\n",
    "k_list = np.arange(0, 20 + 1, dtype=int)\n",
    "error_list = np.array([np.abs(T(f, a, b, 2**k) - true_value) for k in k_list])\n",
    "\n",
    "epsilon = np.argmax(error_list < 10 ** (-3))\n",
    "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axis[0].plot(k_list, error_list)\n",
    "axis[0].set_xticks(k_list)\n",
    "axis[0].set_xlabel(r\"Number of sub-intervals ($\\log_2$)\")\n",
    "axis[0].set_ylabel(\"Absolute approximation error\")\n",
    "axis[0].axvline(epsilon, color=\"red\", label=r\"$k_{\\epsilon < 10^{-3}}$\")\n",
    "axis[0].legend()\n",
    "\n",
    "x = np.linspace(a, 1, 1000)\n",
    "y = f(x)\n",
    "axis[1].plot(x, y)\n",
    "axis[1].fill_between(x, y, alpha=0.5)\n",
    "axis[1].set_xlabel(\"x\")\n",
    "axis[1].set_ylabel(\"f(x)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The left graph shows the approximation error for different quanitites of subintervals,\n",
    "with a red vertical line at the point where we achieve the desired error. The right \n",
    "graph shows the function evaluated on a small fraction of the integrated \n",
    "interval ($[0,1]$ versus $[0, 100]$). \n",
    "\n",
    "We see that for all but the smallest values of $x$, $f(x)$ is almost zero. As the graph \n",
    "is relatively flat in this region, the integrals evaluated on these subintervals is \n",
    "more accurate, and contributes less to the total integral, than subintervals closer to \n",
    "zero. \n",
    "\n",
    "The subintervals near zero -- in particular, the first subinterval -- are less \n",
    "straightforward. In order for the first subinterval to give an accurate estimate, the \n",
    "subinterval must be small enough that the rapid drop in the function appears \n",
    "approximately linear. It is evident from the graph that naive spacing for this first \n",
    "interval can easily result in a poor approximation.\n",
    "\n",
    "To summarise, most of the integration interval is easy to evaluate accurately, except \n",
    "for near zero. Since subintervals are allocated uniformly, in order to evaluate this \n",
    "tricky region accurately, we must increase the subinterval density globally. This \n",
    "explains the large requirement on number of sub-intervals observed in the first plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (b)\n",
    "\n",
    "To improve the convergence rate of the above problem, we may use an adaptive strategy, as discussed in the book and the lecture. Consider the following formulas for approximate integration\n",
    "$$I_1(f,a,b) = T(f,a,b,1)$$\n",
    "$$I_2(f,a,b) = T(f,a,b,2).$$\n",
    "Show, based on the precise error estimates for the trapezoid rule from the book/lecture that the error in $I_2$ can be estimated by a formula of the form \n",
    "$$E_2 = C (I_1 - I_2)$$\n",
    "and determine the constant $C$ (if you can't find $C$, you may take $C = 0.5$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "For an interval $[a,b]$, denote the midpoint by $m = \\frac{a + b}{2}$, and let $h = \n",
    "(b - a)$. \n",
    "\n",
    "Evaluating a third-order Taylor expansion around $m$ at the endpoints, $a$ and $b$ \n",
    "gives: \n",
    "\n",
    "\\begin{align*}\n",
    "f(a) &= f(m) - f'(m)(h/2) + \\frac{1}{2}f''(m)(h/2)^2 - \\frac{1}{6}f^{(3)}(m)(h/2)^3 + O(h^4) \\\\\n",
    "f(b) &= f(m) + f'(m)(h/2) + \\frac{1}{2}f''(m)(h/2)^2 + \\frac{1}{6}f^{(3)}(m)(h/2)^3 + O(h^4) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Whose sum cancels odd-powered terms, producing:\n",
    "\n",
    "$$\n",
    "f(a) + f(b) = 2f(m) + \\frac{1}{2}f''(m)(h/2)^2 + O(h^4)\n",
    "$$\n",
    "\n",
    "From the lectures, we obtain an expression for the integral of $f$ as a\n",
    "fourth-order Taylor expansion around $m$:\n",
    "\n",
    "$$\n",
    "I(f) = f(m)h + \\frac{1}{24}f''(m)h^3 + \\frac{1}{1920}f^{(4)}(m)h^5 + O(h^7)\n",
    "$$\n",
    "\n",
    "$I_1$ and $I_2$ are expressed in terms of the composite trapezoid formula, as:\n",
    "\n",
    "\\begin{align*}\n",
    "    I_1(f) &= \\frac{h}{2}\\left[f(a) + f(b)\\right] \\\\\n",
    "    I_2(f) &= \\frac{h}{2}\\left[\\frac{f(a) + f(b)}{2} + f(m)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "We first identify a simplifed form of the target difference, $I_1(f) - I_2(f)$, with \n",
    "sustitution of $f(a) + f(b)$ by the aforestated Taylor expansion:\n",
    "\n",
    "\\begin{align*}\n",
    "I_1(f) - I_2(f) &= \\frac{h}{2}\\left[\\frac{f(a) + f(b)}{2} - f(m)\\right] \\\\\n",
    "&= \\frac{h}{2}\\left[\\frac{2f(m) + f''(m)(h/2)^2 + O(h^4)}{2} - f(m)\\right] \\\\\n",
    "&= \\frac{1}{16}f''(m)h^3 + O(h^5)\n",
    "\\end{align*}\n",
    "\n",
    "Finally, we show that the error in $I_2(f)$, denoted $E_2(f) = I_2(f) - I(f)$, is \n",
    "estimated by a scalar multiple of this difference:\n",
    "\n",
    "\\begin{align*}\n",
    "I_2(f) - I(f) &= \\frac{h}{2}\\left[\\frac{f(a) + f(b)}{2} + f(m)\\right] - I(f) \\\\\n",
    "&= \\frac{h}{2}\\left[\\frac{2f(m) + \\frac{1}{4}f''(m)h^2 + O(h^4)}{2} + f(m)\\right] - I(f) \\\\\n",
    "&= \\frac{1}{24}f''(m)h^3 + O(h^5) \\\\\n",
    "&= \\frac{2}{3}\\left[\\frac{1}{16}f''(m)h^3\\right] + O(h^5) \\\\\n",
    "&= \\frac{2}{3}\\left[I_1(f) - I_2(f)\\right] + O(h^5)\n",
    "\\end{align*}\n",
    "\n",
    "So we see that $\\frac{2}{3}(I_1(f) - I_2(f))$ is a reasonable approximation to $E_2(f)$.\n",
    "\n",
    "Giving us $C = \\frac{2}{3}$.\n",
    "\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## (c)\n",
    "An adaptive strategy for computing the integral on an interval $[a,b]$ now is: Compute $I_2$ and $E_2$, and accept $I_2$ as an approximation when the estimated error $E_2$ is less or equal than a desired tolerance $\\epsilon$.  Otherwise, apply the procedure to \n",
    "$\\int_a^{\\frac{b+a}{2}} f(x) \\, dx$ and $\\int_{\\frac{b+a}{2}}^b f(x) \\, dx$ with tolerances $\\frac{\\epsilon}{2}$.\n",
    "\n",
    "Write a recursive python routine that implements the adaptive strategy.\n",
    "\n",
    "Then apply this routine to the function $x^{-3}$ with $a, b, \\epsilon$ as before. What is the exact error in the obtained approximation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2 / 3\n",
    "\n",
    "\n",
    "def T_recursive(f, a, b, epsilon):\n",
    "    \"\"\"\n",
    "    Recursive trapezoidal rule for a function f over the interval [a, b] with an error tolerance epsilon.\n",
    "    \"\"\"\n",
    "    I_one = T(f, a, b, 1)\n",
    "    I_two = T(f, a, b, 2)\n",
    "\n",
    "    midpoint = (b + a) / 2\n",
    "    if midpoint <= a or midpoint >= b:\n",
    "        return I_two\n",
    "\n",
    "    if abs(C * (I_one - I_two)) <= epsilon:\n",
    "        return I_two\n",
    "\n",
    "    right = T_recursive(f, midpoint, b, epsilon / 2)\n",
    "    left = T_recursive(f, a, midpoint, epsilon / 2)\n",
    "\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time(func, args):\n",
    "    \"\"\"\n",
    "    Compute the time taken to run a function with arguments.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    return time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1 / 10, 100.0\n",
    "true_value = 1 / 2 * (1 / 0.1**2 - 1 / 100**2)\n",
    "EPSILON = 10**-3\n",
    "k = 18\n",
    "m = 2**k\n",
    "\n",
    "approx_int_recur = T_recursive(f, a, b, EPSILON)\n",
    "approx_int = T(f, a, b, m)\n",
    "\n",
    "compute_time_recur = compute_time(T_recursive, (f, a, b, EPSILON))\n",
    "compute_time_simple = compute_time(T, (f, a, b, m))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": [\"Recursive\", \"Simple\", \"True value\"],\n",
    "        \"Approximation\": [approx_int_recur, approx_int, true_value],\n",
    "        \"Error\": [\n",
    "            np.abs(approx_int_recur - true_value),\n",
    "            np.abs(approx_int - true_value),\n",
    "            \"\",\n",
    "        ],\n",
    "        \"Time\": [compute_time_recur, compute_time_simple, \"\"],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The error with the recursive function is smaller than the non-recursive one, at the \n",
    "cost of a longer compute time. We note that the error resulting from the recursive \n",
    "function is significantly lower than the required threshold \n",
    "($1.7\\cdot 10^{-4} < 10^{-3}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## (d)\n",
    "\n",
    "Modify the code of (c) so that the number of function evaluations is counted. Optimize your implementation such that no unnecessary function evaluations are performed.\n",
    "\n",
    "Compare the number of function evaluations used in the adaptive strategy of (c) with the result of (a). \n",
    "(*Hint*: To count the number of function evaluations, you may use a global variable.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Unnecessary function evaluations exist in the following places:\n",
    "- $I_1$ and $I_2$ both evaluate $f(a)$ and $f(b)$\n",
    "- $f(a)$, $f(mid)$ and $f(b)$ are evaluated by the left and right recursive calls, as the new endpoints.\n",
    "\n",
    "We eliminate these calls by modifying:\n",
    "- The recursive function to take optional $f(a)$ and $f(b)$ as parameters\n",
    "- The trapezoid rule function to take $f(a)$, $f(b)$, and $f(mid)$ (when used with two subintervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa, fb = f(a), f(b)\n",
    "\n",
    "\n",
    "def T_recursive_optimised(f, a, b, epsilon, fa=None, fb=None):\n",
    "    \"\"\"\n",
    "    Optimised recursive trapezoidal rule for a function f over the interval [a, b] with an error tolerance epsilon.\n",
    "    \"\"\"\n",
    "    fmid = f((a + b) / 2)\n",
    "    I_one = T(f, a, b, 1, fa=fa, fb=fb)\n",
    "    I_two = T(f, a, b, 2, fa=fa, fmid=fmid, fb=fb)\n",
    "    C = 6 / 8\n",
    "\n",
    "    midpoint = (b + a) / 2\n",
    "    if midpoint <= a or midpoint >= b:\n",
    "        return I_two\n",
    "\n",
    "    if abs(C * (I_one - I_two)) <= epsilon:\n",
    "        return I_two\n",
    "\n",
    "    return T_recursive_optimised(\n",
    "        f, a, midpoint, epsilon / 2, fa, fmid\n",
    "    ) + T_recursive_optimised(f, midpoint, b, epsilon / 2, fmid, fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(func, args):\n",
    "    \"\"\"\n",
    "    Count the number of function evaluations.\n",
    "    \"\"\"\n",
    "    global FUNC_EVAL\n",
    "    FUNC_EVAL = 0\n",
    "    func(*args)\n",
    "    return FUNC_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_val = np.zeros(4)\n",
    "eval_val[0] = func_eval(T_recursive, (f, a, b, EPSILON))\n",
    "eval_val[1] = func_eval(T, (f, a, b, m))\n",
    "eval_val[2] = func_eval(T_recursive_optimised, (f, a, b, EPSILON, fa, fb))\n",
    "\n",
    "compute_time_recur_opt = compute_time(T_recursive_optimised, (f, a, b, EPSILON, fa, fb))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": [\"Recursive\", \"Simple\", \"Recursive (opt)\", \"True value\"],\n",
    "        \"Approximation\": [approx_int_recur, approx_int, approx_int_recur, true_value],\n",
    "        \"Error\": [\n",
    "            np.abs(approx_int_recur - true_value),\n",
    "            np.abs(approx_int - true_value),\n",
    "            np.abs(approx_int_recur - true_value),\n",
    "            \"\",\n",
    "        ],\n",
    "        \"Time\": [compute_time_recur, compute_time_simple, compute_time_recur_opt, \"\"],\n",
    "        \"Function evaluations\": eval_val,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.bar(\n",
    "    [\n",
    "        \"Recursive\",\n",
    "        \"Simple\",\n",
    "        \"Recursive (opt)\",\n",
    "    ],\n",
    "    eval_val[:-1],\n",
    "    color=[\"tab:blue\", \"tab:orange\", \"tab:red\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Algorithm\")\n",
    "ax.set_ylabel(r\"Number of $f(x)$ evaluations\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "As seen in the image above the _Simple_ method is the least efficient, requiring significantly more evaluations of $f(x)$ than the others. The _Recursive_ algorithm improves on this, but the _Recursive (opt)_ method is by far the most efficient, needing the fewest evaluations of $f(x)$.\n",
    "In compute time the _Simple_ algorithm is still the fastest, even over the _Recursive (opt)_ method, but results in greater error. Whereby the _Recursive (opt)_ is faster than the _Recursive_ method and gives equivalent error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## (e)\n",
    "In the course of executing the recursive procedure, some subintervals are refined (split into two subintervals) while others aren't as a result of the choices made by the algorithm. It turns out that the choices made by this algorithm are not always optimal. Other algorithms, that decide in a different way which subinterval needs to be refined, may be more efficient in the sense that they require less function evaluations (while using the same formulas for the approximate integral and the approximate error associated with a subinterval).\n",
    "\n",
    "Can you explain why this is the case? Devise an alternative, non-recursive algorithm that addresses this issue and should to lead a more efficient integral computation. Describe your approach and algorithm in about 5 to 10 sentences (bullet points).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "The recursive approach is short-sighted, and requires uniform error across subintervals.\n",
    "This is evident in the fact that each recursive call provides an updated error \n",
    "requirement of $\\epsilon/2$. In reality, small total error across the integral $[a,b]$ \n",
    "does not require uniformly low error in subintervals. We may choose to allow larger \n",
    "error in some areas, in which the integral is difficult to calculate, and offset this \n",
    "with lower error in others, where the integral is relatively easier. \n",
    "\n",
    "For instance, in the function studied here, we observed earlier in the notebook that \n",
    "most subintervals on the interval $[0.1, 100]$ contribute very little to the total \n",
    "integral. Consequentially, their contribution to the total error is also small. Despite \n",
    "this, the recursive algorithm assumes that the intervals $[0.1,50.05]$ and $[50.05,100]$ \n",
    "contribute equally to the error, and places identically strict error requirements \n",
    "on their recursive calls.\n",
    "\n",
    "We describe the following algorithm which attempts to address this issue:\n",
    "1. Divide the interval $[a,b]$ into two subintervals.\n",
    "2. Estimate the integral on each subinterval.\n",
    "3. Estimate the error on each subinterval, and the resulting total error.\n",
    "4. While the total error exceeds a pre-defined threshold:\n",
    "    1. Subdivide the subinterval with the largest error.\n",
    "    2. Estimate the integrals on each of the two new subintervals.\n",
    "    3. In the total (summed) integral estimate, replace the contribution of the original subinterval with those of the new ones.\n",
    "    4. Estimate the error in each of the two new subintervals.\n",
    "\n",
    "This algorithm retains a global view of the estimation error on the whole interval \n",
    "$[a,b]$. In the context of the function studied in this notebook, we would expect to \n",
    "see less work spent improving estimates in the interval $[1,100]$, and more in the \n",
    "subintervals close to zero. Unlike the recursive algorithm; however, this algorithm \n",
    "does not require that each individual subinterval has low-error -- only that the total \n",
    "sum does. This results in fewer function evaluations to achieve the same error bound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
